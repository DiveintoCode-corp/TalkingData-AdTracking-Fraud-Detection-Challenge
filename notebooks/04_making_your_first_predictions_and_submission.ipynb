{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to use previous learning materials to create predictions on the test dataset and make your first submission.\n",
    "\n",
    "We will use the prediction mechanism demonstrated in **02_read_data_by_chunks_and_make_predictions.ipynb** to create estimations of the target based on the **app** feature.\n",
    "\n",
    "At the end of this notebook you will know how to :\n",
    " - use a groupby statement to create target predictions\n",
    " - create test predictions in a gzip format\n",
    " \n",
    "A public kaggle kernel has been created to help you submit these simple predictions to the LeaderBoard:\n",
    "\n",
    "https://www.kaggle.com/ogrellier/basic-predictions-using-target-encoding-on-app\n",
    "\n",
    "This will make it simpler for you to fork the script and use it on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please change the file_path so that it points to where the train file is on your system  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../input/train.csv.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the hard work you have done in the first notebook you can define the best data types for each columns.\n",
    "\n",
    "Again in this notebook we will exclude all time related columns. \n",
    "\n",
    "Here are the data types definition: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'ip': 'uint32',\n",
    "        'app': 'uint16',\n",
    "        'device': 'uint16',\n",
    "        'os': 'uint16',\n",
    "        'channel': 'uint16',\n",
    "        'is_attributed': 'uint8'\n",
    "    }\n",
    "cols = [f_ for f_ in dtypes.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating simple statistics with the app feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to calculate the probability a given **app**lication will be attributed.\n",
    "In other words we will try to compute :\n",
    "$$P\\left ( is\\_attributed= 1\\mid app \\right )$$\n",
    "\n",
    "To do this we have to go though all training samples and sum up the number of times is_attributed=1 for each **app**lication and count the number of occurences of each **app**lication in the train file.\n",
    "\n",
    "As shown in a previous notebook, the simplest way to do this on the entire train.csv file is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 Chunks have been read in   0.2 minute\n",
      "  2 Chunks have been read in   0.4 minute\n",
      "  3 Chunks have been read in   0.6 minute\n",
      "  4 Chunks have been read in   0.8 minute\n",
      "  5 Chunks have been read in   1.0 minute\n",
      "  6 Chunks have been read in   1.2 minute\n",
      "  7 Chunks have been read in   1.4 minute\n",
      "  8 Chunks have been read in   1.6 minute\n",
      "  9 Chunks have been read in   1.8 minute\n",
      " 10 Chunks have been read in   1.8 minute\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>3248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1230.0</td>\n",
       "      <td>5796274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5661.0</td>\n",
       "      <td>21642136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10261.0</td>\n",
       "      <td>33911780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>126275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27263.0</td>\n",
       "      <td>375533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>205.0</td>\n",
       "      <td>2464136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1182.0</td>\n",
       "      <td>1764954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6875.0</td>\n",
       "      <td>3731948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18823.0</td>\n",
       "      <td>16458268.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sum       count\n",
       "app                     \n",
       "0     1005.0      3248.0\n",
       "1     1230.0   5796274.0\n",
       "2     5661.0  21642136.0\n",
       "3    10261.0  33911780.0\n",
       "4        5.0    126275.0\n",
       "5    27263.0    375533.0\n",
       "6      205.0   2464136.0\n",
       "7     1182.0   1764954.0\n",
       "8     6875.0   3731948.0\n",
       "9    18823.0  16458268.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create app_average and make it None\n",
    "import time\n",
    "app_average = None\n",
    "start_time=time.time()\n",
    "chunksize=20000000\n",
    "for i_chunk, df in enumerate(pd.read_csv(file_path, chunksize=chunksize, dtype=dtypes, usecols=['app', 'is_attributed'])):\n",
    "    # Make the groupby statement\n",
    "    # The groupby statement uses sum and count to be able to compute averages over all samples\n",
    "    the_group = df.groupby(\"app\").agg(['sum', 'count'])\n",
    "    the_group.columns = the_group.columns.droplevel(0)\n",
    "    if app_average is None:\n",
    "        app_average = the_group\n",
    "    else:\n",
    "        # pandas .add method makes sure apps that are not in both the_group and app_average\n",
    "        # take value of 0 before the addition takes place\n",
    "        app_average = the_group.add(app_average, fill_value=0.0)\n",
    "\n",
    "    # Free memory by deleting the current DataFrame\n",
    "    del df, the_group\n",
    "    gc.collect()\n",
    "    \n",
    "    # Display the time we spent so far\n",
    "    print(\"%3d Chunks have been read in %5.1f minute\" \n",
    "          % (i_chunk + 1, (time.time() - start_time) / 60))\n",
    "    \n",
    "app_average.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the average per **app**lication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_average['average'] = app_average['sum'] / app_average['count'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the test dataset and make predictions\n",
    "\n",
    "To perform this action we need to read the test file by chunks, as we did with the train file, and **map** the **app**lication with the average calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 Chunks have been read in   0.1 minute\n",
      "  2 Chunks have been read in   0.1 minute\n",
      "  3 Chunks have been read in   0.2 minute\n",
      "  4 Chunks have been read in   0.2 minute\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "# Create place holders for sample ids and predictions to be able to create the prediction file\n",
    "# ids = None\n",
    "# predictions = None \n",
    "predictions = None\n",
    "# PLEASE CHANGE THE TEST FILE PATH TO YOUR OWN SETTINGS\n",
    "test_file_path = '../input/test.csv.zip'\n",
    "chunksize = 5000000\n",
    "# Read the test file by chunks\n",
    "for i_chunk, df in enumerate(pd.read_csv(test_file_path, chunksize=chunksize, dtype=dtypes, usecols=['click_id', 'app'])):\n",
    "    if predictions is None:\n",
    "        predictions = df[['click_id']] # double square brackets are used to return a DataFrame and not a Series\n",
    "        predictions['is_attributed'] = df['app'].map(app_average['average']).astype(np.float32)\n",
    "    else:\n",
    "        curr_preds = df[['click_id']] # double square brackets are used to return a DataFrame and not a Series\n",
    "        curr_preds['is_attributed'] = df['app'].map(app_average['average']).astype(np.float32)\n",
    "        # Stack predictions and current predictions\n",
    "        predictions: pd.DataFrame = pd.concat([predictions, curr_preds], axis=0)\n",
    "        # free memory\n",
    "        del curr_preds\n",
    "        \n",
    "    # Free memory by deleting the current DataFrame\n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    # Display the time we spent so far\n",
    "    print(\"%3d Chunks have been read in %5.1f minute\" \n",
    "          % (i_chunk + 1, (time.time() - start_time) / 60))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our predictions we need to store them in a file for submission.\n",
    "\n",
    "In this contest the submission file is quite big. To reduce its size, both for storage and submission over the web,we will use the following arguments:\n",
    " - float_format : it is used to cut the decimals of floats\n",
    " - compression : pandas can store files in a compressed format called gzip\n",
    " \n",
    "Writing this file can take some time! On my disk the file takes 108778KB.\n",
    "\n",
    "In the following statement:\n",
    " - **float_format** limits the number of decimal to 6\n",
    " - **compression** tells pandas to compress the file in gzip format\n",
    " - **index=False** tells pandas only to write the features themeselves in the file without the DataFrame index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('app_predictions.csv.gz', float_format='%.6f', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to avoid compressing the file or sending it through the web, which may also take some time, the best is to log into your Kaggle account and create kernel. You can then submit the result directly to the Leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Please use previous code to create test predictions for :\n",
    " - ip\n",
    " - device\n",
    " - channel\n",
    " - os\n",
    " \n",
    "And give us your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
